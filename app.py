import asyncio
import streamlit as st
import os
from dotenv import load_dotenv
from agents import Runner, set_default_openai_key
from tools import deep_research
from my_agents import create_research_agent, create_elaboration_agent

# .envãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯èª­ã¿è¾¼ã‚€
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="é«˜åº¦ãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", page_icon="ğŸ”", layout="wide")

# APIã‚­ãƒ¼ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = os.getenv("OPENAI_API_KEY", "")
if "firecrawl_api_key" not in st.session_state:
    st.session_state.firecrawl_api_key = os.getenv("FIRECRAWL_API_KEY", "")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼è¨­å®š
with st.sidebar:
    st.title("APIè¨­å®š")
    openai_api_key = st.text_input("OpenAI APIã‚­ãƒ¼", value=st.session_state.openai_api_key, type="password")
    firecrawl_api_key = st.text_input(
        "Firecrawl APIã‚­ãƒ¼", value=st.session_state.firecrawl_api_key, type="password"
    )
    if openai_api_key:
        st.session_state.openai_api_key = openai_api_key
        set_default_openai_key(openai_api_key)
    if firecrawl_api_key:
        st.session_state.firecrawl_api_key = firecrawl_api_key

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
st.title("ğŸ” ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
st.markdown("ã“ã®ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã¯OpenAI Agents SDKã¨Firecrawlã‚’ä½¿ç”¨ã—ã¦åŒ…æ‹¬çš„ãªãƒªã‚µãƒ¼ãƒã‚’è¡Œã„ã¾ã™")

# ãƒªã‚µãƒ¼ãƒãƒˆãƒ”ãƒƒã‚¯å…¥åŠ›
research_topic = st.text_input("ãƒªã‚µãƒ¼ãƒãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", placeholder="ä¾‹: AIã®æœ€æ–°å‹•å‘")

# è©³ç´°è¨­å®šã®å±•é–‹å¯èƒ½ã‚»ã‚¯ã‚·ãƒ§ãƒ³
with st.expander("è©³ç´°è¨­å®š"):
    col1, col2, col3 = st.columns(3)
    with col1:
        max_depth = st.slider(
            "ãƒªã‚µãƒ¼ãƒã®æ·±ã•",
            min_value=1,
            max_value=5,
            value=3,
            help="å€¤ãŒé«˜ã„ã»ã©è©³ç´°ãªãƒªã‚µãƒ¼ãƒãŒè¡Œã‚ã‚Œã¾ã™ãŒã€æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™",
        )
    with col2:
        time_limit = st.slider(
            "æ™‚é–“åˆ¶é™ï¼ˆç§’ï¼‰",
            min_value=60,
            max_value=300,
            value=180,
            help="ãƒªã‚µãƒ¼ãƒã®æœ€å¤§æ™‚é–“ï¼ˆç§’ï¼‰",
        )
    with col3:
        max_urls = st.slider(
            "æ¤œç´¢ã™ã‚‹URLæ•°ã®ä¸Šé™",
            min_value=5,
            max_value=20,
            value=10,
            help="åˆ†æã™ã‚‹URLã®æœ€å¤§æ•°",
        )


async def run_research_process(topic: str, max_depth: int, time_limit: int, max_urls: int):
    """å®Œå…¨ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒªã‚µãƒ¼ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"""
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ
    research_agent = create_research_agent([deep_research])
    elaboration_agent = create_elaboration_agent()
    # ã‚¹ãƒ†ãƒƒãƒ—1: æœ€åˆã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹åˆæœŸãƒªã‚µãƒ¼ãƒ
    with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1: åˆæœŸãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œä¸­..."):
        research_prompt = f"""
        ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦è©³ç´°ãªãƒªã‚µãƒ¼ãƒã‚’è¡Œã£ã¦ãã ã•ã„: {topic}
        ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§deep_researchãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„:
        - max_depth: {max_depth}
        - time_limit: {time_limit}
        - max_urls: {max_urls}
        
        ã‚ãªãŸã®ç™ºè¦‹ã‚’æ•´ç†ã•ã‚ŒãŸæ§‹é€ ã®ãƒ¬ãƒãƒ¼ãƒˆã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
        """
        research_result = await Runner.run(research_agent, research_prompt)
        initial_report = research_result.final_output

    # åˆæœŸãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    # åˆæœŸãƒ¬ãƒãƒ¼ãƒˆã‚’å±•é–‹å¯èƒ½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è¡¨ç¤º
    with st.expander("åˆæœŸãƒªã‚µãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã®å‡ºåŠ›ï¼‰"):
        st.markdown(initial_report)

    # ã‚¹ãƒ†ãƒƒãƒ—2: 2ç•ªç›®ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ãƒ¬ãƒãƒ¼ãƒˆã®å¼·åŒ–
    with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2: è¿½åŠ æƒ…å ±ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’å¼·åŒ–ä¸­..."):
        elaboration_input = f"""
        ãƒªã‚µãƒ¼ãƒãƒˆãƒ”ãƒƒã‚¯: {topic}
        åˆæœŸãƒªã‚µãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆ:
        {initial_report}
        ã“ã®ãƒªã‚µãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆã«è¿½åŠ æƒ…å ±ã€ä¾‹ã€ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã€ã‚ˆã‚Šæ·±ã„æ´å¯Ÿã‚’åŠ ãˆã¦å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚
        å­¦è¡“çš„å³å¯†ã•ã¨äº‹å®Ÿã®æ­£ç¢ºã•ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚
        """
        elaboration_result = await Runner.run(elaboration_agent, elaboration_input)
        enhanced_report = elaboration_result.final_output

    return enhanced_report


# ãƒ¡ã‚¤ãƒ³ãƒªã‚µãƒ¼ãƒãƒ—ãƒ­ã‚»ã‚¹
if st.button(
    "ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹", disabled=not (openai_api_key and firecrawl_api_key and research_topic)
):
    if not openai_api_key or not firecrawl_api_key:
        st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ä¸¡æ–¹ã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not research_topic:
        st.warning("ãƒªã‚µãƒ¼ãƒãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
            report_placeholder = st.empty()

            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ³ãƒ†ãƒŠ
            status_container = st.container()
            with status_container:
                st.subheader("ãƒªã‚µãƒ¼ãƒçŠ¶æ³:")

            # ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒªã‚µãƒ¼ãƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
            enhanced_report = asyncio.run(
                run_research_process(research_topic, max_depth, time_limit, max_urls)
            )

            # å¼·åŒ–ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
            report_placeholder.markdown("## å¼·åŒ–ã•ã‚ŒãŸãƒªã‚µãƒ¼ãƒãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡ºåŠ›ï¼‰")
            report_placeholder.markdown(enhanced_report)

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
            st.download_button(
                "ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                enhanced_report,
                file_name=f"{research_topic.replace(' ', '_')}_report.md",
                mime="text/markdown",
            )
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    "OpenAI Agents SDKã¨Firecrawlã‚’æ´»ç”¨ - ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³æ–™é‡‘ãªã—ã§ã‚ãªãŸè‡ªèº«ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒªã‚µãƒ¼ãƒã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³"
)
